{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Labeling in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the transition, start and emission matrix . The states stand for high and low.  The HMM model is given in the assignment itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "P= np.array([[0.6, 0.4],[0.5,0.5]])\n",
    "\n",
    "S= np.array([0.5, 0.5])\n",
    "\n",
    "O= np.array([[0.3,0.2,0.2,0.3],[0.2,0.3,0.3,0.2]])\n",
    "\n",
    "state={}\n",
    "state[0]='L'\n",
    "state[1]='H'\n",
    "\n",
    "DNA={}\n",
    "DNA['A']=0\n",
    "DNA['C']=1\n",
    "DNA['G']=2\n",
    "DNA['T']=3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A stupid attempt to show you why the exhaustive search is a bad, bad option for HMM modelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import time \n",
    "def exhaustive_search(sequence):\n",
    "    \n",
    "    M= len(sequence)\n",
    "    state_len= len(S)\n",
    "\n",
    "    # track the best sequence and its score\n",
    "    best=(None,float('-inf'))\n",
    "    \n",
    "    # basically loop will run for |states|^M \n",
    "    for ss in product(range(state_len),repeat=M):\n",
    "        #print(ss)\n",
    "        score= S[ss[0]]*O[ss[0],DNA[sequence[0]]]\n",
    "        \n",
    "        for i in range(1,M):\n",
    "            score*= P[ss[i-1],ss[i]]*O[ss[i],DNA[sequence[i]]]\n",
    "    \n",
    "        if score > best[1]:\n",
    "            best= (ss,score)\n",
    "    \n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the sequence GGC of length 3 time taken was 0.0s\n",
      "The sequence H,H,H gave the best score of 0.003375\n",
      "\n",
      "\n",
      "For the sequence GGCAAGATCAT of length 11 time taken was 0.014s\n",
      "The sequence H,H,H,L,L,L,L,L,L,L,L gave the best score of 1.3774950719999997e-09\n",
      "\n",
      "\n",
      "For the sequence GAGAGGAGAGAGAGAGAGA of length 19 time taken was 4.381s\n",
      "The sequence H,L,L,L,H,H,L,L,L,L,L,L,L,L,L,L,L,L,L gave the best score of 1.3326697514029538e-16\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sequences=['GGC','GGCAAGATCAT','GAGAGGAGAGAGAGAGAGA']\n",
    "\n",
    "import time\n",
    "for sequence in sequences:\n",
    "    \n",
    "    t=time.time()\n",
    "    best=exhaustive_search(sequence)\n",
    "    t2=time.time()-t\n",
    "    \n",
    "    print('For the sequence '+ sequence+ ' of length '+ str(len(sequence))+' time taken was '+ str(round(t2,3))+'s' )\n",
    "    print('The sequence '+ ','.join([state[k] for k in best[0]])+ ' gave the best score of '+ str(best[1]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset for this assignment: Brown corpus tagged with the Universal Tagset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This will be your training set. The remaining 100 sentences will be used as your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words(M):  55907\n",
      "Number of tags(N):  12\n",
      "{'DET': 136724, 'NOUN': 275075, 'ADJ': 83581, 'VERB': 182380, 'ADP': 144483, '.': 147231, 'ADV': 56115, 'CONJ': 38067, 'PRT': 29759, 'PRON': 49174, 'NUM': 14853, 'X': 1369}\n",
      "2727\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank,brown\n",
    "\n",
    "corpus = brown.tagged_sents(tagset='universal')[:-100] \n",
    "#print(corpus[0])\n",
    "tag_dict={}\n",
    "word_dict={}\n",
    "\n",
    "for sent in corpus:\n",
    "    for elem in sent:\n",
    "        w = elem[0]\n",
    "        tag= elem[1]\n",
    "        if w not in word_dict:\n",
    "            word_dict[w]=0\n",
    "        if tag not in tag_dict:\n",
    "            tag_dict[tag]=0\n",
    "        word_dict[w]+=1\n",
    "        tag_dict[tag]+=1\n",
    "\n",
    "print('Number of words(M): ',len(word_dict))\n",
    "print('Number of tags(N): ',len(tag_dict))\n",
    "print(tag_dict)\n",
    "        \n",
    "test_data= brown.tagged_sents(tagset='universal')[-10:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Model (Assignment task 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn transition,start and emission matrices from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('START', 'START'), ('DET', 'The'), ('NOUN', 'Fulton'), ('NOUN', 'County'), ('ADJ', 'Grand'), ('NOUN', 'Jury'), ('VERB', 'said'), ('NOUN', 'Friday'), ('DET', 'an'), ('NOUN', 'investigation'), ('ADP', 'of'), ('NOUN', \"Atlanta's\"), ('ADJ', 'recent'), ('NOUN', 'primary'), ('NOUN', 'election'), ('VERB', 'produced'), ('.', '``'), ('DET', 'no'), ('NOUN', 'evidence'), ('.', \"''\"), ('ADP', 'that'), ('DET', 'any'), ('NOUN', 'irregularities'), ('VERB', 'took'), ('NOUN', 'place'), ('.', '.'), ('END', 'END'), ('START', 'START'), ('DET', 'The'), ('NOUN', 'jury')]\n"
     ]
    }
   ],
   "source": [
    "brown_tags_words = [ ]\n",
    "for sent in corpus:  \n",
    "    brown_tags_words.append( (\"START\", \"START\") )\n",
    "    brown_tags_words.extend([ (tag, word) for (word, tag) in sent ])\n",
    "    brown_tags_words.append( (\"END\", \"END\") )\n",
    "    \n",
    "print(brown_tags_words[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Transition matrix:\n",
      "[[0.005917029928907872, 0.6263860039203066, 0.23980427723004008, 0.06470700096544864, 0.009091308036628536, 0.012748310464878149, 0.017502413621602646, 0.0006436324273719318, 0.002011351335537287, 0.009895848570843451, 0.009764196483426465, 0.0013969749275913519], [0.01550122693810779, 0.14934835953830775, 0.012894665091338726, 0.1589093883486322, 0.24437698809415614, 0.2835844769608289, 0.026370989730073617, 0.0596782695628465, 0.01782786512769245, 0.01978369535581205, 0.008077796964464238, 0.0003308188675815687], [0.005850611981191898, 0.65281583134923, 0.05690288462688889, 0.01746808485182039, 0.08844115289360022, 0.10033380792285328, 0.009643339993539201, 0.037604240198131154, 0.019286679987078403, 0.003804692454026633, 0.006987233940728156, 0.0004905421088524905], [0.16292904923785503, 0.0975710055927185, 0.05753920386007238, 0.1843020067989911, 0.1691797346200241, 0.08060642614321746, 0.10326241912490404, 0.014376576378988924, 0.06559381511130606, 0.054923785502796356, 0.008975764886500712, 0.00018094089264173704], [0.4555968522248292, 0.25848023642919926, 0.08268792868365137, 0.041257448973235605, 0.020293044856488307, 0.0097450911179862, 0.015489711592367268, 0.0018894956500072673, 0.014230047825695757, 0.06968985970667829, 0.03013503318729539, 0.000449879916668397], [0.0677031331716826, 0.08292411244914454, 0.028920539831964735, 0.07657354769036412, 0.06516290726817042, 0.10723964382500968, 0.043564195040446646, 0.06929926442121565, 0.018331737202083802, 0.046247053949236235, 0.012076261113488328, 0.001256528856015377], [0.07361668003207698, 0.032861088835427245, 0.13622026196204223, 0.24031007751937986, 0.14204758086073244, 0.17000801924619086, 0.09687249398556536, 0.017321571772253408, 0.028655439721999465, 0.048329323710237904, 0.013311948676824378, 8.910273545397844e-05], [0.1511282738329787, 0.24380697191793416, 0.11211810754721938, 0.19536606509575222, 0.07334436651167678, 0.02075288307457903, 0.09136522447264034, 0.0002626947224630257, 0.02503480705072635, 0.06753881314524392, 0.01867759476712113, 0.000551658917172354], [0.08363856312376088, 0.03578749285930307, 0.018918646459894484, 0.6225007560737928, 0.09066164857690111, 0.07658187439094055, 0.036123525656104036, 0.012231593803555227, 0.01125709869283242, 0.0068214657750596455, 0.00510769851137471, 6.720655936019356e-05], [0.0175499247569854, 0.008886810102899906, 0.00951722454955871, 0.7064098914060276, 0.0555781510554358, 0.10357099280107374, 0.05403261886362712, 0.01142880383942734, 0.023752389474112335, 0.008195387806564444, 0.0009761255948265344, 0.0], [0.013128660876590587, 0.38025988015889045, 0.05917996364370834, 0.04551269103884737, 0.1310846293678045, 0.2710563522520703, 0.02039991920824076, 0.038308759173231, 0.005251464350636235, 0.008483134720258533, 0.021746448528916718, 0.00020197939810139365], [0.005113221329437546, 0.0547845142439737, 0.0029218407596785976, 0.052593133674214754, 0.053323593864134405, 0.2731921110299489, 0.006574141709276844, 0.022644265887509132, 0.007304601899196494, 0.006574141709276844, 0.0007304601899196494, 0.5127830533235939]]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# conditional frequency distribution of the word given the tags\n",
    "CFD_tag_words = nltk.ConditionalFreqDist(brown_tags_words)\n",
    "# conditional probability distribution of the word given the tags\n",
    "# P(wi | ti)\n",
    "CPD_tag_words = nltk.ConditionalProbDist(CFD_tag_words, nltk.MLEProbDist)\n",
    "\n",
    "brown_tags = [tag for (tag, word) in brown_tags_words ]\n",
    "\n",
    "# make conditional frequency distribution: count(t{i-1} ti)\n",
    "CFD_tags= nltk.ConditionalFreqDist(nltk.bigrams(brown_tags))\n",
    "# make conditional probability distribution, using maximum likelihood estimate:\n",
    "# P(ti | t{i-1})\n",
    "CPD_tags = nltk.ConditionalProbDist(CFD_tags, nltk.MLEProbDist)\n",
    "\n",
    "tag_trans_matrix=[]\n",
    "j=-1\n",
    "for tag1 in tag_dict:\n",
    "    tag_trans_matrix.append([])\n",
    "    j=j+1\n",
    "    for tag2 in tag_dict:\n",
    "        tag_trans_matrix[j].append(CPD_tags[tag1].prob(tag2))\n",
    "print(\"State Transition matrix:\")\n",
    "print(tag_trans_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi Algorithm to get the best POS tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The given sentence: ['you', \"can't\", 'very', 'well', 'sidle', 'up', 'to', 'people', 'on', 'the', 'street', 'and', 'ask', 'if', 'they', 'want', 'to', 'buy', 'a', 'hot', 'Bodhisattva', '.']\n",
      "\n",
      "The POS tags: ['PRON', 'VERB', 'ADV', 'ADV', 'VERB', 'PRT', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', 'CONJ', 'VERB', 'ADP', 'PRON', 'VERB', 'PRT', 'VERB', 'DET', 'ADJ', 'NOUN', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def Viterbi(sentence):\n",
    "    sentlen = len(sentence)\n",
    "    distinct_tags = set(brown_tags)\n",
    "\n",
    "    viterbi = [ ]\n",
    "    backpointer = [ ]\n",
    "\n",
    "    viterbi_init = { }\n",
    "    backpointer_init = { }\n",
    "\n",
    "    for tag in distinct_tags:\n",
    "        if tag == \"START\": continue\n",
    "        viterbi_init[ tag ] = CPD_tags[\"START\"].prob(tag) * CPD_tag_words[tag].prob(sentence[0])\n",
    "        backpointer_init[ tag ] = \"START\"\n",
    "    viterbi.append(viterbi_init)\n",
    "    backpointer.append(backpointer_init)\n",
    "\n",
    "    for wordindex in range(1, len(sentence)):\n",
    "        cur_viterbi = { }\n",
    "        cur_backpointer = { }\n",
    "        prev_viterbi = viterbi[-1]\n",
    "            \n",
    "        for tag in distinct_tags:\n",
    "            if tag == \"START\": continue\n",
    "            if sentence[wordindex] not in word_dict.keys():\n",
    "                best_prevtag = max(prev_viterbi.keys(),key = lambda prevtag: \\\n",
    "                    prev_viterbi[ prevtag ] * CPD_tags[prevtag].prob(tag) *0.0001)\n",
    "                cur_viterbi[tag] = prev_viterbi[ best_prevtag ] *\\\n",
    "                                    CPD_tags[best_prevtag].prob(tag) * 0.0001\n",
    "            else:\n",
    "                best_prevtag = max(prev_viterbi.keys(),key = lambda prevtag: \\\n",
    "                    prev_viterbi[ prevtag ] * CPD_tags[prevtag].prob(tag) * \n",
    "                                    CPD_tag_words[tag].prob(sentence[wordindex]))\n",
    "                cur_viterbi[tag] = prev_viterbi[ best_prevtag ] *\\\n",
    "                                    CPD_tags[best_prevtag].prob(tag) *\\\n",
    "                                    CPD_tag_words[tag].prob(sentence[wordindex])\n",
    "            cur_backpointer[tag] = best_prevtag\n",
    "\n",
    "        viterbi.append(cur_viterbi)\n",
    "        backpointer.append(cur_backpointer)\n",
    "\n",
    "    prev_viterbi = viterbi[-1]\n",
    "    best_prevtag = max(prev_viterbi.keys(),key = lambda prevtag: prev_viterbi[ prevtag ] *\\\n",
    "                       CPD_tags[prevtag].prob(\"END\"))\n",
    "\n",
    "    prob_best_seq = prev_viterbi[ best_prevtag ] * CPD_tags[ best_prevtag].prob(\"END\")\n",
    "    best_tag_seq = [ \"END\", best_prevtag ]\n",
    "\n",
    "    backpointer.reverse()\n",
    "    current_best_tag = best_prevtag\n",
    "    for bp in backpointer:\n",
    "        best_tag_seq.append(bp[current_best_tag])\n",
    "        current_best_tag = bp[current_best_tag]\n",
    "\n",
    "    best_tag_seq.reverse()\n",
    "    \n",
    "    return best_tag_seq[1:-1]\n",
    "    \n",
    "#sentence = ['I', \"can't\", 'drive', 'a', 'car', '.']\n",
    "sentence = ['you', \"can't\", 'very', 'well', 'sidle', 'up', 'to', 'people', 'on', 'the', 'street', 'and', 'ask', 'if', 'they', 'want', 'to', 'buy', 'a', 'hot', 'Bodhisattva', '.']\n",
    "\n",
    "tag_seq=Viterbi(sentence)\n",
    "print(\"\\nThe given sentence:\",sentence)\n",
    "print(\"\\nThe POS tags:\",tag_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results with HMM using Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', \"can't\", 'very', 'well', 'sidle', 'up', 'to', 'people', 'on', 'the', 'street', 'and', 'ask', 'if', 'they', 'want', 'to', 'buy', 'a', 'hot', 'Bodhisattva', '.']\n",
      "\n",
      "Actual tags:\n",
      "************\n",
      "['PRON', 'VERB', 'ADV', 'ADV', 'VERB', 'ADP', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', 'CONJ', 'VERB', 'ADP', 'PRON', 'VERB', 'PRT', 'VERB', 'DET', 'ADJ', 'NOUN', '.', 'ADV', '.', 'ADP', 'PRT', 'VERB', 'PRT', 'VERB', 'X', 'X', 'X', 'ADV', 'ADV', 'ADP', 'NOUN', '.', 'NOUN', '.', 'NOUN', 'NOUN', '.', 'DET', 'NOUN', 'NOUN', '.', 'NOUN', 'NOUN', '.', 'NOUN', '.', 'CONJ', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'PRT', 'VERB', '.', 'PRON', 'VERB', 'VERB', 'PRT', 'VERB', 'VERB', 'ADV', '.', 'DET', 'NOUN', '.', 'ADP', 'PRON', 'VERB', 'ADJ', 'ADV', 'PRT', 'VERB', 'DET', 'NOUN', '.', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', 'PRT', 'VERB', 'ADP', 'DET', 'ADJ', '.', 'VERB', 'PRON', 'PRT', '.', 'PRT', 'NOUN', 'CONJ', 'DET', 'NOUN', '.', 'ADP', 'PRON', 'VERB', 'VERB', 'ADP', 'PRON', 'PRT', 'VERB', 'DET', 'ADJ', '.', 'ADV', 'PRON', '.', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', 'VERB', 'VERB', '.', 'CONJ', 'ADP', 'PRON', 'VERB', 'ADP', 'DET', 'NOUN', 'CONJ', '.', 'VERB', '.', 'VERB', 'PRT', 'ADP', 'DET', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'ADP', 'NOUN', '.', 'PRON', 'VERB', 'DET', 'VERB', 'NOUN', 'CONJ', 'DET', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', '.', 'ADJ', '.', 'PRON', 'VERB', 'DET', 'NOUN', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'CONJ', 'DET', 'NOUN', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'NOUN', '.', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', 'VERB', 'DET', 'NOUN', 'ADV', 'ADJ', '.', 'ADP', 'DET', 'PRON', 'VERB', 'ADJ', 'ADP', 'NOUN', 'ADP', 'DET', 'ADJ', '.', 'ADJ', 'NOUN', '.', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'VERB', 'VERB', '.']\n",
      "\n",
      "Predicted tags:\n",
      "************\n",
      "['PRON', 'VERB', 'ADV', 'ADV', 'VERB', 'PRT', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', 'CONJ', 'VERB', 'ADP', 'PRON', 'VERB', 'PRT', 'VERB', 'DET', 'ADJ', 'NOUN', '.', 'ADV', '.', 'ADP', 'PRT', 'VERB', 'PRT', 'VERB', 'DET', 'X', 'VERB', 'ADV', 'ADV', 'ADP', 'NOUN', '.', 'NOUN', '.', 'NOUN', 'NOUN', '.', 'DET', 'NOUN', 'VERB', '.', 'NOUN', 'NOUN', '.', 'NOUN', '.', 'CONJ', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'PRT', 'VERB', '.', 'PRON', 'VERB', 'VERB', 'PRT', 'VERB', 'VERB', 'ADV', '.', 'DET', 'NOUN', '.', 'ADP', 'PRON', 'VERB', 'ADV', 'ADV', 'PRT', 'VERB', 'DET', 'NOUN', '.', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', 'PRT', 'VERB', 'ADP', 'DET', 'ADJ', '.', 'VERB', 'PRON', 'PRT', '.', 'PRT', 'NOUN', 'CONJ', 'DET', 'NOUN', '.', 'ADP', 'PRON', 'VERB', 'VERB', 'ADP', 'PRON', 'PRT', 'VERB', 'DET', 'ADJ', '.', 'ADJ', 'ADJ', 'ADJ', 'NOUN', 'NOUN', '.', 'NOUN', 'ADP', 'DET', 'NOUN', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', 'VERB', 'VERB', '.', 'CONJ', 'ADP', 'PRON', 'VERB', 'ADP', 'DET', 'NOUN', 'CONJ', '.', 'NOUN', '.', 'VERB', 'PRT', 'ADP', 'DET', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'ADP', 'NOUN', '.', 'PRON', 'VERB', 'DET', 'NOUN', 'NOUN', 'CONJ', 'DET', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', '.', 'NOUN', '.', 'PRON', 'VERB', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'CONJ', 'DET', 'NOUN', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'NOUN', '.', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', 'VERB', 'DET', 'NOUN', 'ADV', 'ADJ', '.', 'ADP', 'DET', 'PRON', 'VERB', 'ADJ', 'ADP', 'NOUN', 'ADP', 'DET', 'ADJ', '.', 'ADJ', 'NOUN', '.', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'VERB', 'NOUN', '.']\n",
      "\n",
      "Total testing accuracy:  0.9330543933054394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_list=[]\n",
    "y_true=[]\n",
    "y_pred=[]\n",
    "i=-1\n",
    "for sent in test_data:\n",
    "    test_list.append([])\n",
    "    i=i+1\n",
    "    for elem in sent:\n",
    "        test_list[i].append(elem[0])\n",
    "        y_true.append(elem[1])\n",
    "        \n",
    "print(test_list[0])\n",
    "        \n",
    "print(\"\\nActual tags:\")\n",
    "print(\"************\")\n",
    "print(y_true)\n",
    "\n",
    "for sent in test_list:\n",
    "    y_pred=y_pred+Viterbi(sent)\n",
    "    \n",
    "print(\"\\nPredicted tags:\")\n",
    "print(\"************\")\n",
    "print(y_pred)\n",
    "print(\"\\nTotal testing accuracy: \",accuracy_score(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module to implement CRF (Assignment Part 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature definition using each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install sklearn-crfsuite # install this please\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "train_sents= corpus\n",
    "\n",
    "def word2features(sent,i):\n",
    "    word = sent[i][0]\n",
    "    features ={\n",
    "    'bias': 1.0,\n",
    "    'word':word,\n",
    "    'is_first': i == 0,\n",
    "    'is_last': i == len(sent) - 1,\n",
    "    'is_capitalized': word[0].upper() == word[0],\n",
    "    'is_all_caps': word.upper() == word,\n",
    "    'is_all_lower': word.lower() == word,\n",
    "    'prefix-1': word[0],\n",
    "    'prefix-2': word[:2],\n",
    "    'prefix-3': word[:3],\n",
    "    'suffix-1': word[-1],\n",
    "    'suffix-2': word[-2:],\n",
    "    'suffix-3': word[-3:],\n",
    "    'prev_word': '' if i == 0 else sent[i - 1][0],\n",
    "    'next_word': '' if i == len(sent) - 1 else sent[i + 1][0],\n",
    "    'has_hyphen': '-' in word,\n",
    "    'is_numeric': word.isdigit(),\n",
    "    'capitals_inside': word[1:].lower() != word[1:]\n",
    "    }\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent,i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for i,label in sent]\n",
    "\n",
    "#print(sent2features(corpus[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[sent2features(s) for s in train_sents]\n",
    "y_train=[sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test=[sent2features(s) for s in test_data]\n",
    "y_test=[sent2labels(s) for s in test_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of CRF using sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results with CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnab/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/arnab/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9749640807442314"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "labels=list(crf.classes_)\n",
    "\n",
    "metrics.flat_f1_score(y_test, y_pred, \n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          .      1.000     1.000     1.000        33\n",
      "          X      1.000     1.000     1.000         3\n",
      "        ADJ      1.000     0.944     0.971        18\n",
      "        ADP      0.962     0.926     0.943        27\n",
      "        ADV      0.900     1.000     0.947         9\n",
      "       VERB      0.972     1.000     0.986        35\n",
      "        DET      0.971     1.000     0.985        33\n",
      "       CONJ      1.000     0.857     0.923         7\n",
      "       NOUN      1.000     0.980     0.990        51\n",
      "       PRON      1.000     0.917     0.957        12\n",
      "        PRT      0.846     1.000     0.917        11\n",
      "        NUM      0.000     0.000     0.000         0\n",
      "\n",
      "avg / total      0.977     0.975     0.975       239\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnab/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/arnab/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(labels, key=lambda name: (name[1:], name[0]))\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
